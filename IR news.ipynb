{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "rpoTvrzquZXm",
    "outputId": "443d670d-37d1-428e-9b27-205f48578917"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\spyro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\spyro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import re\n",
    "from math import log\n",
    "nltk.download('stopwords')\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "CNs1ACZxhL42",
    "outputId": "0ba0d49d-b51f-4ee7-f16a-bada60945c4c"
   },
   "outputs": [],
   "source": [
    "#Preprocessing function\n",
    "\n",
    "def preprocessing(df):\n",
    "    \n",
    "    c=[]\n",
    "    for i in range(len(df)):\n",
    "        text=str(df[i])\n",
    "        #print(text, i)\n",
    "        \n",
    "        #punctuation removal , lowercase\n",
    "        text=re.sub('[^a-zA-Z0-9]',' ',text)\n",
    "        text=re.sub('\\s([?.!\"](?:\\s|$))', r'\\1',text)\n",
    "        text=str(text).lower()\n",
    "        text=word_tokenize(text)\n",
    "        \n",
    "        \n",
    "        # lemmatisation\n",
    "        lemmatiser = WordNetLemmatizer()\n",
    "        tokens = [lemmatiser.lemmatize(t) for t in text]\n",
    "        tokens = [t for t in tokens if t] # ensure no empty space\n",
    "        \n",
    "        # stopword removal\n",
    "        stop = set(stopwords.words('english'))\n",
    "        tokens = [t for t in tokens if t not in stop]\n",
    "        \n",
    "        \n",
    "        text=' '.join(tokens)\n",
    "        c.append(text)\n",
    "        #print(c)\n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_length(text):\n",
    "    try:\n",
    "        return len(text.split(' '))\n",
    "    except AttributeError:\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not in use\n",
    "\n",
    "def count_terms(df):\n",
    "   \n",
    "    c=[]\n",
    "    for i in range(len(df)):\n",
    "        counts = dict()\n",
    "        words=str(df[i])\n",
    "        tokens = nltk.word_tokenize(words)\n",
    "        for word in tokens:\n",
    "            if word in counts:\n",
    "                counts[word] += 1\n",
    "            else:\n",
    "                counts[word] = 1\n",
    "        c.append(counts)\n",
    "        #print(counts)\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency of word in index, i.e. number of documents that contain word - NOT IN USE\n",
    "def get_index_freq(word,df):\n",
    "    index_freq=0\n",
    "    for i in range(len(df)):\n",
    "        if word in df['tf'][i]:\n",
    "            index_freq+=1\n",
    "    return index_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    " def getfrequencies(corpus):\n",
    "    \n",
    "    tf = []\n",
    "    docf = {}\n",
    "    idf = {}\n",
    "    doc_len = []\n",
    "    corpus_size = 0\n",
    "    \n",
    "    for line in corpus:\n",
    "        corpus_size += 1\n",
    "        doc_len.append(len(line))\n",
    "\n",
    "        # compute tf (term frequency) per document\n",
    "        freq = {}\n",
    "        tokens = nltk.word_tokenize(line)\n",
    "        for word in tokens:\n",
    "           # print(word)\n",
    "            word_count = freq.get(word, 0) + 1\n",
    "            freq[word] = word_count\n",
    "\n",
    "        tf.append(freq)\n",
    "\n",
    "        # compute df (document frequency) per term\n",
    "        for word, _ in freq.items():\n",
    "            docf_count = docf.get(word, 0) + 1\n",
    "            docf[word] = docf_count\n",
    "\n",
    "    for word, freq in docf.items():\n",
    "        idf[word] = math.log(1 + (corpus_size - freq + 0.5) / (freq + 0.5))\n",
    "\n",
    "    avg_doc_len = sum(doc_len) / corpus_size\n",
    "    \n",
    "    return doc_len,corpus_size,tf,docf,idf,avg_doc_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_preproces(query):\n",
    "    \n",
    "    stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "    tokens = nltk.word_tokenize(query)\n",
    "  \n",
    "    pre = [w for w in tokens if not w in stop_words] \n",
    "  \n",
    "    pre = [] \n",
    "  \n",
    "    for w in tokens: \n",
    "        if w not in stop_words: \n",
    "            pre.append(w.lower()) \n",
    "\n",
    "    return pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(query, corpus,corpus_size, doc_len, tf, idf, avg_doc_len, k1, b ):\n",
    "    s=[]\n",
    "    for line in range(corpus_size):\n",
    "        #print(line)\n",
    "        doclen = doc_len[line]\n",
    "        frequencies = tf[line]\n",
    "        score = 0.0\n",
    "        for term in query:\n",
    "            if term in frequencies:\n",
    "        \n",
    "                freq = frequencies[term]\n",
    "                numerator = idf[term] * freq * (k1 + 1)\n",
    "                denominator = freq + k1 * (1 - b + b * doclen / avg_doc_len)\n",
    "                score += (numerator / denominator)\n",
    "        s.append(score)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spyro\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Create the pandas dataframe\n",
    "df = pd.read_csv(r\"articles.csv\",encoding='utf-8')\n",
    "df.dropna()\n",
    "df=df[:1000]\n",
    "\n",
    "#get unique id's\n",
    "for i in range(len(df)):\n",
    "    df['id'][i] = i+1\n",
    "\n",
    "#Preprocess the data and get the length\n",
    "df['processed_title'] = preprocessing(df['title'])\n",
    "df['processed_content'] = preprocessing(df['content'])\n",
    "df['length'] = df['processed_content'].apply(lambda x: calculate_length(x))\n",
    "\n",
    "#count the terms\n",
    "#df['count_terms']= count_terms(df['processed_content'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "\n",
    "for i in range(len(df)):\n",
    "    corpus.append(df['processed_content'][i])\n",
    "    \n",
    "doc_len,corpus_size,tf,doc_freq,idf,avg_doc_len = getfrequencies(corpus)\n",
    "\n",
    "df['tf']= tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trump', 'presentent', 'america', '?']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Trump Presentent of America?'\n",
    "query = query_preproces(query)\n",
    "query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=1.5\n",
    "b=0.75\n",
    "\n",
    "scor = rank(query, corpus,corpus_size, doc_len, tf, idf, avg_doc_len, k1, b )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>processed_title</th>\n",
       "      <th>processed_content</th>\n",
       "      <th>length</th>\n",
       "      <th>tf</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>104316</td>\n",
       "      <td>858</td>\n",
       "      <td>Trump’s tax plan: massive cuts for the 1% will...</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>Rupert Neate</td>\n",
       "      <td>2016-11-23</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>https://www.theguardian.com/us-news/2016/nov/2...</td>\n",
       "      <td>President Donald Trump is set to give America’...</td>\n",
       "      <td>trump tax plan massive cut 1 usher era dynasti...</td>\n",
       "      <td>president donald trump set give america riches...</td>\n",
       "      <td>569</td>\n",
       "      <td>{'president': 2, 'donald': 1, 'trump': 19, 'se...</td>\n",
       "      <td>5.942126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>104413</td>\n",
       "      <td>955</td>\n",
       "      <td>Election diary: Trump as Stalin, the future of...</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>David Smith</td>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>https://www.theguardian.com/us-news/2016/oct/2...</td>\n",
       "      <td>Mark Wednesday in your diary. The Trump family...</td>\n",
       "      <td>election diary trump stalin future tv wikileak...</td>\n",
       "      <td>mark wednesday diary trump family host officia...</td>\n",
       "      <td>519</td>\n",
       "      <td>{'mark': 1, 'wednesday': 4, 'diary': 1, 'trump...</td>\n",
       "      <td>5.927724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>104422</td>\n",
       "      <td>964</td>\n",
       "      <td>The Guardian view on America’s choice: Don’t v...</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>2016-11-07</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>https://www.theguardian.com/commentisfree/2016...</td>\n",
       "      <td>It is make your mind up time for America. A ho...</td>\n",
       "      <td>guardian view america choice vote trump elect ...</td>\n",
       "      <td>make mind time america hopeful incrementally b...</td>\n",
       "      <td>421</td>\n",
       "      <td>{'make': 3, 'mind': 1, 'time': 5, 'america': 6...</td>\n",
       "      <td>5.912647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>104332</td>\n",
       "      <td>874</td>\n",
       "      <td>Mark Cuban insults Trump before backing ’true ...</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>Lauren Gambino</td>\n",
       "      <td>2016-07-30</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>https://www.theguardian.com/us-news/2016/jul/3...</td>\n",
       "      <td>The battle of the brash billionaires is on. En...</td>\n",
       "      <td>mark cuban insult trump backing true leader hi...</td>\n",
       "      <td>battle brash billionaire entrepreneur mark cub...</td>\n",
       "      <td>347</td>\n",
       "      <td>{'battle': 1, 'brash': 1, 'billionaire': 1, 'e...</td>\n",
       "      <td>5.742731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>103857</td>\n",
       "      <td>399</td>\n",
       "      <td>Trump deletes tweet with image of the star of ...</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>Jamiles Lartey</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>https://www.theguardian.com/us-news/2016/jul/0...</td>\n",
       "      <td>Donald Trump deleted an image of Hillary Clint...</td>\n",
       "      <td>trump deletes tweet image star david hillary c...</td>\n",
       "      <td>donald trump deleted image hillary clinton sta...</td>\n",
       "      <td>271</td>\n",
       "      <td>{'donald': 1, 'trump': 9, 'deleted': 1, 'image...</td>\n",
       "      <td>5.692855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>103874</td>\n",
       "      <td>416</td>\n",
       "      <td>Leicester’s woes continue as Hazard, Costa and...</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>Dominic Fifield</td>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>https://www.theguardian.com/football/2016/oct/...</td>\n",
       "      <td>There was a moment just after the   here when ...</td>\n",
       "      <td>leicester woe continue hazard costa moses fire...</td>\n",
       "      <td>wa moment frustration finally overcame claudio...</td>\n",
       "      <td>439</td>\n",
       "      <td>{'wa': 13, 'moment': 1, 'frustration': 1, 'fin...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>103875</td>\n",
       "      <td>417</td>\n",
       "      <td>French woman accused of murdering daughter on ...</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>Kim Willsher</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>https://www.theguardian.com/world/2016/jun/20/...</td>\n",
       "      <td>A French woman who left her baby daughter to d...</td>\n",
       "      <td>french woman accused murdering daughter beach ...</td>\n",
       "      <td>french woman left baby daughter drown beach bl...</td>\n",
       "      <td>351</td>\n",
       "      <td>{'french': 3, 'woman': 1, 'left': 2, 'baby': 1...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>103876</td>\n",
       "      <td>418</td>\n",
       "      <td>Standing Rock: injured protester’s father says...</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>Julia Carrie Wong</td>\n",
       "      <td>2016-11-23</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>https://www.theguardian.com/us-news/2016/nov/2...</td>\n",
       "      <td>North Dakota law enforcement have blamed prote...</td>\n",
       "      <td>standing rock injured protester father say pol...</td>\n",
       "      <td>north dakota law enforcement blamed protester ...</td>\n",
       "      <td>523</td>\n",
       "      <td>{'north': 6, 'dakota': 8, 'law': 11, 'enforcem...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>103880</td>\n",
       "      <td>422</td>\n",
       "      <td>Fox News is a cesspool of sexism. Firing Roger...</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>Jessica Valenti</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>https://www.theguardian.com/commentisfree/2016...</td>\n",
       "      <td>This week, all signs point to Roger Ailes bein...</td>\n",
       "      <td>fox news cesspool sexism firing roger ailes fix</td>\n",
       "      <td>week sign point roger ailes fired position hea...</td>\n",
       "      <td>277</td>\n",
       "      <td>{'week': 1, 'sign': 1, 'point': 1, 'roger': 1,...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>103959</td>\n",
       "      <td>501</td>\n",
       "      <td>Even basic phone logs can reveal deeply person...</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>Ian Sample</td>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.theguardian.com/science/2016/may/1...</td>\n",
       "      <td>The mass collection of telephone records by go...</td>\n",
       "      <td>even basic phone log reveal deeply personal in...</td>\n",
       "      <td>mass collection telephone record government su...</td>\n",
       "      <td>573</td>\n",
       "      <td>{'mass': 2, 'collection': 2, 'telephone': 4, '...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   id                                              title  \\\n",
       "857      104316  858  Trump’s tax plan: massive cuts for the 1% will...   \n",
       "954      104413  955  Election diary: Trump as Stalin, the future of...   \n",
       "963      104422  964  The Guardian view on America’s choice: Don’t v...   \n",
       "873      104332  874  Mark Cuban insults Trump before backing ’true ...   \n",
       "398      103857  399  Trump deletes tweet with image of the star of ...   \n",
       "..          ...  ...                                                ...   \n",
       "415      103874  416  Leicester’s woes continue as Hazard, Costa and...   \n",
       "416      103875  417  French woman accused of murdering daughter on ...   \n",
       "417      103876  418  Standing Rock: injured protester’s father says...   \n",
       "421      103880  422  Fox News is a cesspool of sexism. Firing Roger...   \n",
       "500      103959  501  Even basic phone logs can reveal deeply person...   \n",
       "\n",
       "    publication             author        date    year  month  \\\n",
       "857    Guardian       Rupert Neate  2016-11-23  2016.0   11.0   \n",
       "954    Guardian        David Smith  2016-10-22  2016.0   10.0   \n",
       "963    Guardian          Editorial  2016-11-07  2016.0   11.0   \n",
       "873    Guardian     Lauren Gambino  2016-07-30  2016.0    7.0   \n",
       "398    Guardian     Jamiles Lartey  2016-07-02  2016.0    7.0   \n",
       "..          ...                ...         ...     ...    ...   \n",
       "415    Guardian    Dominic Fifield  2016-10-15  2016.0   10.0   \n",
       "416    Guardian       Kim Willsher  2016-06-20  2016.0    6.0   \n",
       "417    Guardian  Julia Carrie Wong  2016-11-23  2016.0   11.0   \n",
       "421    Guardian    Jessica Valenti  2016-07-19  2016.0    7.0   \n",
       "500    Guardian         Ian Sample  2016-05-16  2016.0    5.0   \n",
       "\n",
       "                                                   url  \\\n",
       "857  https://www.theguardian.com/us-news/2016/nov/2...   \n",
       "954  https://www.theguardian.com/us-news/2016/oct/2...   \n",
       "963  https://www.theguardian.com/commentisfree/2016...   \n",
       "873  https://www.theguardian.com/us-news/2016/jul/3...   \n",
       "398  https://www.theguardian.com/us-news/2016/jul/0...   \n",
       "..                                                 ...   \n",
       "415  https://www.theguardian.com/football/2016/oct/...   \n",
       "416  https://www.theguardian.com/world/2016/jun/20/...   \n",
       "417  https://www.theguardian.com/us-news/2016/nov/2...   \n",
       "421  https://www.theguardian.com/commentisfree/2016...   \n",
       "500  https://www.theguardian.com/science/2016/may/1...   \n",
       "\n",
       "                                               content  \\\n",
       "857  President Donald Trump is set to give America’...   \n",
       "954  Mark Wednesday in your diary. The Trump family...   \n",
       "963  It is make your mind up time for America. A ho...   \n",
       "873  The battle of the brash billionaires is on. En...   \n",
       "398  Donald Trump deleted an image of Hillary Clint...   \n",
       "..                                                 ...   \n",
       "415  There was a moment just after the   here when ...   \n",
       "416  A French woman who left her baby daughter to d...   \n",
       "417  North Dakota law enforcement have blamed prote...   \n",
       "421  This week, all signs point to Roger Ailes bein...   \n",
       "500  The mass collection of telephone records by go...   \n",
       "\n",
       "                                       processed_title  \\\n",
       "857  trump tax plan massive cut 1 usher era dynasti...   \n",
       "954  election diary trump stalin future tv wikileak...   \n",
       "963  guardian view america choice vote trump elect ...   \n",
       "873  mark cuban insult trump backing true leader hi...   \n",
       "398  trump deletes tweet image star david hillary c...   \n",
       "..                                                 ...   \n",
       "415  leicester woe continue hazard costa moses fire...   \n",
       "416  french woman accused murdering daughter beach ...   \n",
       "417  standing rock injured protester father say pol...   \n",
       "421    fox news cesspool sexism firing roger ailes fix   \n",
       "500  even basic phone log reveal deeply personal in...   \n",
       "\n",
       "                                     processed_content  length  \\\n",
       "857  president donald trump set give america riches...     569   \n",
       "954  mark wednesday diary trump family host officia...     519   \n",
       "963  make mind time america hopeful incrementally b...     421   \n",
       "873  battle brash billionaire entrepreneur mark cub...     347   \n",
       "398  donald trump deleted image hillary clinton sta...     271   \n",
       "..                                                 ...     ...   \n",
       "415  wa moment frustration finally overcame claudio...     439   \n",
       "416  french woman left baby daughter drown beach bl...     351   \n",
       "417  north dakota law enforcement blamed protester ...     523   \n",
       "421  week sign point roger ailes fired position hea...     277   \n",
       "500  mass collection telephone record government su...     573   \n",
       "\n",
       "                                                    tf    scores  \n",
       "857  {'president': 2, 'donald': 1, 'trump': 19, 'se...  5.942126  \n",
       "954  {'mark': 1, 'wednesday': 4, 'diary': 1, 'trump...  5.927724  \n",
       "963  {'make': 3, 'mind': 1, 'time': 5, 'america': 6...  5.912647  \n",
       "873  {'battle': 1, 'brash': 1, 'billionaire': 1, 'e...  5.742731  \n",
       "398  {'donald': 1, 'trump': 9, 'deleted': 1, 'image...  5.692855  \n",
       "..                                                 ...       ...  \n",
       "415  {'wa': 13, 'moment': 1, 'frustration': 1, 'fin...  0.000000  \n",
       "416  {'french': 3, 'woman': 1, 'left': 2, 'baby': 1...  0.000000  \n",
       "417  {'north': 6, 'dakota': 8, 'law': 11, 'enforcem...  0.000000  \n",
       "421  {'week': 1, 'sign': 1, 'point': 1, 'roger': 1,...  0.000000  \n",
       "500  {'mass': 2, 'collection': 2, 'telephone': 4, '...  0.000000  \n",
       "\n",
       "[1000 rows x 15 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scores']= scor\n",
    "df.sort_values(by=['scores'],ascending=False)\n",
    "#df[['scores','title']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PArtD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
